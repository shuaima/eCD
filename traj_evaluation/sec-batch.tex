\subsection{Batch Algorithms}
Batch algorithms essentially apply global distance checking policies for trajectory simplification, and can be either top-down or bottom-up.
Global checking policies enforce batch algorithms to have an entire trajectory first \cite{Meratnia:Spatiotemporal}.

(1) Top-down algorithms recursively divide a trajectory into sub-trajectories until the stopping condition is met.
Algorithms Ramer \cite{Ramer:Split} and Douglas-Peucker (\dpa)  \cite{Douglas:Peucker} are \myblue{extremely} similar, and support all the three distances \ped, \sed and \dad. {Note that \myblue{Ramer and Douglas-Peucker are jointly referred to as ``Ramer-Douglas-Peucker'', and} the \dpa using \sed is also called TD-TR \cite{Meratnia:Spatiotemporal}}.
An improved method of \dpa with a time complexity of $O(n\log n)$, based on \emph{convex hulls}, is proposed in \cite{Hershberger:Speeding}, which is the best \dpa based  algorithm in terms of time complexities, and is designed for \ped only, not for \sed and \dad.

%Variations on the Top-Down algorithm were independently introduced in several fields in the early 1970's. Douglas-Peucker algorithm [9] in cartography and Ramer  algorithm [29] in image processing share the similar routine, and they support all the three ...


(2) Bottom-up algorithms are the natural complement of top-down ones, and they recursively merge adjacent sub-trajectories with the smallest distance, initially $n/2$  sub-trajectories for a trajectory with $n$ points, until the stopping condition is met. In each iteration, the distances of newly generated line segments are recalculated.
To our knowledge, Theo-Pavlidis (\tpa) \cite{Pavlidis:Segment} is the only bottom-up batch \lsa algorithm that supports \ped, \sed and \dad. {Besides, \bumr~\cite{Chen:Fast} using \lissed is also a bottom-up algorithm.}

Note that, compared with top-down algorithms, bottom-up algorithms fit better for trajectories with lower sampling rates, as they typically need more rounds to merge smaller line segments into larger line segments. {\em Batch algorithms basically work for small and medium size trajectories, and we choose {the famous top-down algorithm} \dpa and {the classic bottom-up algorithm} \tpa that all support \ped, \sed and \dad  as the representatives of batch \lsa algorithms}.


%We next review algorithms Douglas-Peucker and Theo Pavlidis evaluated in out experiments.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\vspace{-1ex}
%\subsubsection{Douglas-Peucker Algorithm}

\eat{
%%%%%%%%%%%%%%%%%%%%%Baseline Algorithm
\begin{figure}[tb!]
	%\vspace{-2ex}
	\vspace{1ex}
	\begin{center}
		{\small
			\begin{minipage}{3.3in}
				\myhrule \vspace{-1ex}
				\mat{0ex}{
					{\bf Algorithm}~$\dpa(\dddot{\mathcal{T}}[P_0,\ldots,P_n], \epsilon)$\\
					\sstab
					\bcc \hspace{1ex}\=\For each point $P_i$ ($i\in[0,n]$) in $\dddot{\mathcal{T}}[P_0, \ldots, P_n]$ \Do\\
					\icc \>\hspace{3ex}compute $ped(P_i, {\mathcal{L}})$ between $P_i$ and ${\mathcal{L}}(P_0, P_n)$;\\
					\icc \> \Let $ped(P_k, {\mathcal{L}})$ := $\max \{ped(P_0, {\mathcal{L}}), \ldots, ped(P_n, {\mathcal{L}}) \}$;\\
					\icc \> \If $ped(P_k, {\mathcal{L}}) \le\epsilon$ \Then \\
					\icc \> \hspace{3ex}\Return $\{\mathcal{L}(P_0,P_n)\}$.\\
					\icc \> \Else\\
					\icc \> \hspace{3ex}\Return $\dpa($\trajec{T}$[P_0, \ldots, P_k], \epsilon)\cup\dpa($\trajec{T}$[P_{k}, \ldots, P_n], \epsilon)$.
				}
				\vspace{-2.5ex}
				\myhrule
			\end{minipage}
		}
	\end{center}
	\vspace{-3ex}
	\caption{\small Basic Douglas-Peucker algorithm}
	\label{alg:dp}
	\vspace{-3ex}
\end{figure}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Algorithm Douglas-Peucker  (\dpa) \cite{Douglas:Peucker}}
It is invented for reducing the number of points required to represent a digitized line or its caricature in the context of computer graphics and image processing.
{Originally, it uses \ped, however, it can be easily extended to support \sed and \dad.}


Given a trajectory $\dddot{\mathcal{T}}[P_0, \ldots, P_n]$ and an error bound $\epsilon$,  algorithm \dpa uses the first point $P_0$ and the last point $P_n$ of \trajec{T} as the start point $P_s$ and the end point $P_e$ of the first line segment $\mathcal{L}(P_0, P_n)$, then it calculates the distance $ped(P_i, {\mathcal{L}})$ for each point $P_i$ ($i\in[0,n]$). If $ped(P_k, {\mathcal{L}})$ = $\max \{ped(P_0, {\mathcal{L}}), \ldots, ped(P_n, {\mathcal{L}}) \} \le \epsilon$, then it returns $\{\mathcal{L}(P_0,P_n)\}$. Otherwise, it divides \trajec{T} into two sub-trajectories \trajec{T}$[P_0, \ldots, P_k]$ and \trajec{T}$[P_{k}, \ldots, P_n]$, and recursively compresses these sub-trajectories until the entire trajectory has been considered.
%
The time complexity of \dpa is $\Omega(n)$ in the best case, but is $O(n^2)$ in the worst case.

%The basic \dpa uses \ped, however, it also supports \sed \cite{Meratnia:Spatiotemporal} that runs in the same routine as using \ped. %, except that $ped$ in
%Figure~\ref{alg:dp} is replace by $sed$.



\begin{example}
	\label{exm-alg-lsa}
	Consider the trajectory $\dddot{\mathcal{T}}[P_0,\ldots,P_{10}]$ shown in Figure~\ref{fig:dp}.
	The $\dpa$ Algorithm firstly creates $\vv{P_0P_{10}}$, then it calculates the distance of each point in $\{P_0,\ldots,P_{10}\}$ to $\vv{P_0P_{10}}$.
	It finds that $P_{4}$ has the maximum distance to $\vv{P_0P_{10}}$, which is greater than $\epsilon$. Then it goes to compress sub-trajectories $[P_0, \ldots, P_{4}]$ and $[P_{4}, \ldots, P_{10}]$, separately.
	When using \sed (right), the sub-trajectory $[P_4,\ldots, P_{10}]$ is further split to $[P_4$, $\ldots$, $P_7]$ and $[P_7$, $P_{10}]$.
	Finally, the algorithm outputs two continuous directed line segments $\vv{P_0P_4}$ and $\vv{P_4P_{10}}$ when using \ped, and three continuous directed line segments $\vv{P_0P_4}$, $\vv{P_4P_7}$ and $\vv{P_7P_{10}}$ when using \sed.
\end{example}




\subsubsection{Algorithm Theo-Pavlidis  (\tpa) ~\cite{Pavlidis:Segment}}
It originally employs the global checking policy to output disjoint line segments, and we slightly modify it to have continuous line segments.

Given a trajectory $\dddot{\mathcal{T}}[P_0, \ldots, P_n]$ and an error bound $\epsilon$,
algorithm \tpa begins by creating the finest possible  trajectory approximation: $[P_0, P_1]$, $[P_1, P_2], \ldots,[P_{n-1}, P_n]$, so that $n$ segments are used to approximate the original trajectory.
Next, for each pair of adjacent segments $[P_{s}, P_{s+j}]$ and $[P_{s+j}, P_{s+k}]$ ($0\le s<s+j < s+k \le n$),
the  distance $ped(P_{s+i}, \vv{P_sP_{s+k}})$ of each point $P_{s+i}$ ($0<i<k$) to the line segment $\vv{P_sP_{s+k}}$, is calculated, and the max distance is saved and denoted as the \emph{cost} of merging them.
Then \tpa begins to iteratively merge the adjacent segment pair with the lowest cost
until no cost is below $\epsilon$.
After the pair of adjacent segments $[P_{s}, P_{s+j}]$ and $[P_{s+j}, P_{s+k}]$ are merged to a new segment $[P_{s}, P_{s+k}]$, \tpa needs to recalculate the costs of the new segment with its preceding and successive segments, respectively.
%
Algorithm \tpa runs in $O(n^2/K)$ time, where $K$ is the number of the final segments.
Similar to the \dpa algorithm, the \tpa algorithm originally supports \ped, and it can be easily extended to support \sed and \dad as well.

\begin{figure}[tb!]
	\centering
	\includegraphics[scale=0.425]{Figures/Fig-pavlidis.jpg}\vspace{-1ex}
	\caption{\small The trajectory $\dddot{\mathcal{T}}[P_0, \ldots, P_{10}]$ is compressed by the \pavlidis~algorithm using \ped to two line segments. The triple $(i, j, cost)$ is the $cost$ of merging the line segments $\overline{P_iP_t}$ and $\overline{P_tP_j}$.}	\vspace{-2ex}
	\label{fig:pavlidis}
\end{figure}

\begin{example}
	\label{exm-alg-pavlidis}
	Figure~\ref{fig:pavlidis} is an example of the \tpa algorithm.
	
	\ni (1) Initially, $10$ line segments are created, and for each pair of adjacent segments, the costs of merging them are calculated and saved. For example, the cost of merging $\vv{P_0P_1}$ and $\vv{P_1P_2}$ is $ped(P_{1}, \vv{P_0P_{2}}) = 0.32\epsilon$.
	%
	(2) The cost of merging $\vv{P_6P_7}$ and $\vv{P_7P_8}$ is $0.02\epsilon$, which is the minimal value among all costs. Hence, $\vv{P_6P_7}$ and $\vv{P_7P_8}$ are merged to $\vv{P_6P_8}$. The cost of merging $\vv{P_5P_6}$ and $\vv{P_6P_8}$, and the cost of merging $\vv{P_6P_8}$ and $\vv{P_8P_9}$ are further updated to $0.37\epsilon$ and $0.11\epsilon$, respectively.
	%
	(3) $\vv{P_6P_8}$ and $\vv{P_8P_9}$ are merged to $\vv{P_6P_9}$. The cost of merging $\vv{P_5P_6}$ and $\vv{P_6P_9}$, and the cost of merging $\vv{P_6P_9}$ and $\vv{P_9P_{10}}$ are also updated.
	%
	(4) At last, the algorithm outputs two line segments $\vv{P_0P_4}$ and $\vv{P_4P_{10}}$.
\end{example}



